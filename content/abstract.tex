\pdfbookmark[0]{Abstract}{Abstract}
{\usekomafont{chapter}Abstract}
\label{sec:abstract:abstract}

In this thesis, to build a multi-modal system for language generation and understanding, we study grounded neural language models. 
Literature in psychology informs us that spatial cognition involves different aspects of knowledge that include visual perception and human interaction with the world. This makes spatial descriptions a compelling case for the study of how spatial language is grounded in different kinds of knowledge.
In seven studies, we investigate \emph{what} and \emph{how} neural language models (NLM) encode spatial knowledge. 

In the first study, we explore the traces of functional-geometric distinction of spatial relations in uni-modal NLM.
This distinction is essential since the knowledge about object-specific relations is not grounded in the visible situation. 
Following that, in the second study, we inspect representations of spatial relations in a uni-modal NLM to understand how they capture the concept of space from the corpus.
The predictability of grounding spatial relations from contextual embeddings is vital for the evaluation of grounding in multi-modal language models.
On the argument for the geometric meaning, in the third study, we inspect the spectrum of bounding box annotations on image descriptions. 
We show that less geometrically biased spatial relations are more likely to deviate from the norm of their bounding box features.
In the fourth study, we try to evaluate the degree of grounding in language and vision with adaptive attention.
In the fifth study, we use adaptive attention to understand if and how additional bounding box geometric information could improve the generation of relational image descriptions. 
In the sixth study, we ask if the language model has an ability of systematic generalisation to learn the grounding on the unseen composition of representations.
Then in the seventh study, we show the potentials in using uni-modal knowledge for detecting metaphors in adjective-nouns compositions.

The primary argument of the thesis is built on the fact that spatial expressions in natural language are not always grounded in direct interpretations of the locations. 
We argue that distributional knowledge from corpora of language use and their association with visual features constitute grounding with neural language models. 
Therefore, in a joint model of vision and language, the neural language model provides spatial knowledge that is contextualising the visual representations about locations. 





\clearpage
{\usekomafont{chapter} Sammanfattning (Abstract)}
\label{sec:abstract:abstract-svenska} 

I denna avhandling, för att bygga ett multimodalt system för språkgenerering och förståelse, studerar vi förankrade neurala språkmodeller.
Litteratur i psykologi informerar oss om att rumslig kognition involverar olika aspekter av kunskap som inkluderar visuell uppfattning och mänsklig interaktion med världen. Detta gör att rumsliga beskrivningar är ett bra fall för att studera hur rumsligt språk är förankrat i olika typer av kunskap.
I sju studier undersöker vi \emph{hur} neurala språkmodeller (NLM) kodar rumslig kunskap, och \emph{vad} de kodar.

I den första studien undersöker vi spåren av den funktionella-geometriska distinktion av rumsliga relationer i unimodala NLM.
Denna distinktion är väsentlig eftersom kunskapen om objektspecifika relationer inte är baserad i den synliga situationen.
Därefter, i den andra studien, inspekterar vi representationer av rumsliga relationer i unimodala NLM för att förstå hur de representerar begreppet rymd från en korpus.
Förutsägbarheten av grundläggande rumsliga relationer från kontextuella representationer är avgörande för utvärderingen av förankring i multimodala språkmodeller.
I den tredje studien undersöker vi argument för den geometriska betydelsen genom att inspektera spektrumet av avgränsningsruteannoteringar för bildbeskrivningar.
Vi visar att geometriska relationer med en mindre grad av rumslighet är mer benägna att avvika från normen av avgränsningsfunktionens särdrag.
I den fjärde studien försöker vi utvärdera graden av förankring i språk och syn med adaptiv uppmärksamhet.
I den femte studien använder vi adaptiv uppmärksamhet för att förstå om och hur ytterligare geometrisk information om avgränsningsrutorna kan förbättra generationen av relationella bildbeskrivningar.
I den sjätte studien frågar vi om språkmodeller har en systematisk generaliseringsförmåga att lära sig förankring av osedda sammansättningen av representationer.
Sedan i den sjunde studien visar vi att unimodal kunskap har potential för att upptäcka metaforer i adjektiv-substantivkompositioner.

Avhandlingens huvudargument bygger på det faktum att rumsliga uttryck i naturligt språk inte alltid är baserade på direkta tolkningar av platser.
Vi hävdar att distributionell kunskap från korpusar om språkbruk och deras associering med visuella funktioner utgör förankring för neurala språkmodeller.
Därmed, en modell som använder både visuell information och språk, tillhandahåller neurala språkmodeller rumslig kunskap som kontextualiserar visuella representationer av platser.


\clearpage
{\usekomafont{chapter}List of Publications}\label{sec:abstract:publications} \\



\paragraph{Study 1}
Simon Dobnik, Mehdi Ghanimifard and John Kelleher. 
Exploring the Functional and Geometric Bias of Spatial Relations Using Neural Language Models.
\textit{In Proceedings of the First International Workshop on Spatial Language Understanding, pp. 1-11. 2018.}

\paragraph{Study 2}
Mehdi Ghanimifard and Simon Dobnik. 
\emph{What} a neural language model tells us about spatial relations. 
\textit{In Proceedings of the Combined Workshop on Spatial Language Understanding (SpLU) and Grounded Communication for Robotics (RoboNLP), pp. 71-81. 2019.}

\paragraph{Study 3}
Simon Dobnik and Mehdi Ghanimifard.
Spatial descriptions on a functional-geometric spectrum: the location of objects. 
\textit{Preprint - under review, 2020.}

\paragraph{Study 4}
Mehdi Ghanimifard and Simon Dobnik. 
Knowing When to Look for What and Where: Evaluating Generation of Spatial Descriptions with Adaptive Attention. 
\textit{The European Conference on Computer Vision (ECCV) Workshops, pp. 153-161. Springer, Cham, 2018.}

\paragraph{Study 5}
Mehdi Ghanimifard and Simon Dobnik.
What Goes Into A Word: Generating Image Descriptions With Top-Down Spatial Knowledge
\textit{In INLG 2019-12th International Conference on Natural Language Generation-Long papers. 2019.}

\paragraph{Study 6}
Mehdi Ghanimifard and Simon Dobnik. 
Learning to Compose Spatial Relations with Grounded Neural Language Models. 
\textit{In IWCS 2017-12th International Conference on Computational Semantics-Long papers. 2017.}

\paragraph{Study 7}
Yuri Bizzoni, Stergios Chatzikyriakidis and Mehdi Ghanimifard. 
``Deep'' Learning: Detecting Metaphoricity in Adjective-Noun Pairs.
\textit{In Proceedings of the Workshop on Stylistic Variation, pp. 43-52. 2017.}


